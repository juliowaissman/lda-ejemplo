{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de tópicos\n",
    "\n",
    "## Curso Procesamiento de Lenguaje Natural \n",
    "\n",
    "### Maestría en Ciencia de Datos\n",
    "\n",
    "**Trabajo práctico desarrollado por: [Olivia Gutú](https://oliviagutu.github.io/TEORIA-DE-LA-COMPUTACION/) y [Julio Waissman](http://mat.uson.mx/~juliowaissman/)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta vamos a experimentar con el análisis de tópicos a partir de un corpus en español muy interesante para realizar análisis de tópicos: Una colección de sonetos del siglo de oro español. El córpus incluye mucha información adicional (metadatos) como título, autor, y sobre todo la notación métrica del soneto. Sin embargo para este trabajo no vamos a considerar ninguna de esta información adicional.\n",
    "\n",
    "El corpus se encuentra [en este proyecto de github](https://github.com/bncolorado/CorpusSonetosSigloDeOro) y para su uso académico lo debemos citar correctamente en la referencia:\n",
    "\n",
    "> Navarro-Colorado, Borja; Ribes Lafoz, María, and Sánchez, Noelia (2015) \"Metrical annotation of a large corpus of Spanish sonnets: representation, scansion and evaluation\" 10th edition of the Language Resources and Evaluation Conference 2016 Portorož, Slovenia.[PDF](http://www.dlsi.ua.es/%7Eborja/navarro2016_MetricalPatternsBank.pdf)\n",
    "\n",
    "\n",
    "## 1. Obtención del *corpus*\n",
    "\n",
    "Para obtener el *corpus* es necesario clonar el proyecto original. Desde el punto de mentaje (esto es, la carpeta `curso-pln` centro del contenedor (aunque tambien puede ser por fuera), se usa el comando:\n",
    "\n",
    "```\n",
    "git clone https://github.com/bncolorado/CorpusSonetosSigloDeOro.git\n",
    "```\n",
    "\n",
    "Una vez clonado, es necesario extraer la información de los archivos `xml`. La generación del *corpus* sin normalizar ya la dejo desarollada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et # Para manejar buffers con estructura xml\n",
    "import os\n",
    "\n",
    "# Si guardaste los sonetos en otra dirección, \n",
    "# aqui es donde debes de cambiarlos\n",
    "archivos_path = \"./CorpusSonetosSigloDeOro/\"\n",
    "\n",
    "def lee_soneto(archivo):\n",
    "    soneto = \"\"\n",
    "    arbol = et.parse(archivo)\n",
    "    raiz = arbol.getroot()\n",
    "    for poema in raiz.find('{http://www.tei-c.org/ns/1.0}text'):\n",
    "        if poema.tag == '{http://www.tei-c.org/ns/1.0}body':\n",
    "            for parrafo in poema:\n",
    "                if parrafo.tag == '{http://www.tei-c.org/ns/1.0}lg':\n",
    "                    for linea in parrafo:\n",
    "                        soneto += (linea.text + '\\n')\n",
    "                    soneto += '\\n'\n",
    "    return soneto\n",
    "\n",
    "corpus_sonetos = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(archivos_path):\n",
    "    if not dirnames:\n",
    "        for filename in filenames:\n",
    "            if filename[-4:] == '.xml':\n",
    "                corpus_sonetos.append(lee_soneto(dirpath + '/' + filename))\n",
    "            \n",
    "len(corpus_sonetos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta varias veces la celda de abajo para ver en forma aleatoria si los sonetos se descargaron correcatmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(corpus_sonetos[random.randint(0, 5077)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Procesaiento de texto\n",
    "\n",
    "Ahora es necesario normalizar el texto con fin de utilizarlo en modelado de tópicos.\n",
    "\n",
    "El texto lo vamos a tratar con al menos los siguientes requisitos:\n",
    "\n",
    "1. Utilizar todas las palabras en minúsculas\n",
    "1. Eliminar los signos de puntuación\n",
    "2. Eliminar palabras vacias\n",
    "3. Eliminar las palabras que no aportan significados en la poesía. \n",
    "    \n",
    "Realiza esta normalización utilizando el módulo *spacy* con el modelo `es_core_news_sm`, pero sientete con la libertad de cargar el modelo \n",
    "`es_core_news_md` o inclusive el modelo `es_core_news_lg`. \n",
    "\n",
    "El corpus procesado (*normalizado* también se le dice) se guardará en una lista de textos que llamaremos `corpus_tratado`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesa_poema(doc): \n",
    "    \n",
    "    return [\n",
    "        token.norm_ for token in doc\n",
    "        if token.is_alpha and not token.like_num and not token.is_stop and\n",
    "           token.pos_ in ['PROPN', 'NOUN', 'VERB', 'ADJ']\n",
    "    ]\n",
    "\n",
    "corpus_tratado = [procesa_poema(doc) for doc in nlp.pipe(corpus_sonetos)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y utiliza esta celda para probar si se normalizaron vien los sontetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, 5077)\n",
    "print(i)\n",
    "print(corpus_sonetos[i])\n",
    "print(\"********************\")\n",
    "print(corpus_tratado[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelado de tópicos con LDA\n",
    "\n",
    "Ahora, ya con el corpus tratado, desarrolla tu modelo LDA en *gensim*, siguiendo los siguientes pasos:\n",
    "\n",
    "1. Crea un diccionario con el corpus tratado, donde elimines a todas las\n",
    "   palabras que no aparezcan en al menos `min_df` documentos, y las palabras que \n",
    "   aparezcan el más del `max_df` porciento de documentos (por default `min_df = 5`\n",
    "   y `max_df = 0.3`).\n",
    "2. Genera un corpus listo para su uso, aplicando el metodo de bolsa de palabras.\n",
    "3. Aplica el método para modelar con LDA. Establece el número de iteraciones para\n",
    "   el método de estimación así como el numero de pasos que realiza el algoritmo\n",
    "   de optimización iterativa (por default 100 y 5, respectivamente).\n",
    "   \n",
    "Guarda el modelo en la variable `modelo_lda` (opcionalmente puedes guardar el modelo si lo quieres usar más adelante)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gensim import models, corpora\n",
    "\n",
    "# Genera el diccionario de palabras\n",
    "diccionario = corpora.Dictionary(corpus_tratado)\n",
    "diccionario.filter_extremes(no_below=5, no_above=0.3)\n",
    " \n",
    "# Extrae las características en forma de BOW\n",
    "corpus = [diccionario.doc2bow(doc) for doc in corpus_tratado]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora hacemos el modelado de tópicos con LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de tópicos\n",
    "n_topicos = 10\n",
    "\n",
    "# Genera el modelo LDA\n",
    "modelo_lda = models.LdaModel(corpus=corpus, num_topics=n_topicos, id2word=diccionario, iterations=100, passes=10)\n",
    "\n",
    "# Si quieres guardar el modelo se hace esto\n",
    "#modelo_lda.save(\"sonetosLDA.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos usar otros métodos como el de *Hierachical Dirichlet Process*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_hdp = models.hdpmodel.HdpModel(corpus, diccionario, T=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora veamos los modelos como se definen por sus primeras 5 palabras clave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for (i, topico) in modelo_lda.print_topics(num_topics=n_topicos, num_words=5):\n",
    "    print(10 * \"-\" + \"topico {}\".format(i) + 20 * \"-\")\n",
    "    print(topico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, topico) in modelo_hdp.print_topics(num_words=5):\n",
    "    print(10 * \"-\" + \"topico {}\".format(i) + 20 * \"-\")\n",
    "    print(topico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora veamos como se clasifica un documento utilizando tanto LDA como HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, 5077)\n",
    "\n",
    "poema = corpus_sonetos[i]\n",
    "ids = diccionario.doc2bow(corpus_tratado[i])\n",
    "\n",
    "print(\"El soneto: \\n\\n\" + poema)\n",
    "\n",
    "topicos_lda = modelo_lda[ids]\n",
    "topicos_lda.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "topicos_hdp = modelo_hdp[ids]\n",
    "topicos_hdp.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"Pertenece a los tópicos (con el modelo LDA)\")\n",
    "for (topico, peso) in topicos_lda:\n",
    "    print(\"\\tTopico {} con un peso de {}\".format(topico, peso))\n",
    "\n",
    "print(\"Pertenece a los tópicos (con el modelo HDP)\")\n",
    "for (topico, peso) in topicos_hdp:\n",
    "    print(\"\\tTopico {} con un peso de {}\".format(topico, peso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede obtener la lista de palabras que describen a cada tópico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor aún, utiliza *pyLDAvis* para visualizar y analizar los tópicos desarrollados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "vis_data = gensimvis.prepare(modelo_lda, corpus, diccionario)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(modelo_hdp, corpus, diccionario)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluando modelos\n",
    "\n",
    "Para evaluar un modelo, la forma más sencilla es utilizando el modelo para evaluar la perplejidad del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El logaritomo de la perplejidad del corpus al modelo LDA es {modelo_lda.log_perplexity(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro método es analizando la [coherencia de los tópicos](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf), ponemos algunos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lda = models.CoherenceModel(model=modelo_lda, texts=corpus_tratado, coherence='c_v')\n",
    "cm_hdp = models.CoherenceModel(model=modelo_hdp, texts=corpus_tratado, coherence='c_v')\n",
    "\n",
    "\n",
    "print(\"Coherencia del modelo LDA (C_V): {}\".format(cm_lda.get_coherence()))\n",
    "for (topico, coherencia) in enumerate(cm.get_coherence_per_topic()):\n",
    "    print(\"\\tTópico {}, coherencia {}\".format(topico, coherencia))\n",
    "\n",
    "print(\"\\n\\nCoherencia del modelo HDP (C_V): {}\".format(cm_hdp.get_coherence()))\n",
    "for (topico, coherencia) in enumerate(cm.get_coherence_per_topic()):\n",
    "    print(\"\\tTópico {}, coherencia {}\".format(topico, coherencia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la coherencia se puede obtener el conjunto de palabras que mejor definen cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Las palabra que definen los tópicos en LDA\\n\")\n",
    "t_palabras = cm_lda.top_topics_as_word_lists(model=modelo_lda, dictionary=diccionario)\n",
    "for (topico, palabras) in enumerate(t_palabras):\n",
    "    print(f\"{topico} - {', '.join(palabras)}\")\n",
    "    \n",
    "print(\"\\n\\nLas palabra que definen los tópicos en HDP\\n\")\n",
    "t_palabras = cm_hdp.top_topics_as_word_lists(model=modelo_hdp, dictionary=diccionario)\n",
    "for (topico, palabras) in enumerate(t_palabras):\n",
    "    print(f\"{topico} - {', '.join(palabras)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Responde a las preguntas siguientes\n",
    "\n",
    "Cada pregunta implica experimentación y reflexión, por favor extiende lo que consideres necesario tus explicaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. ¿Cual es el número de tópicos que consideras te ofrece una mejor separación entre ellos, y mejor significado (dejando al resto de los parámetros en valores por default)? ¿Porqué? ¿Algunos tópicos son redundantes entre si? ¿Podrías asignarle un nombre a cada tópico?\n",
    "\n",
    "_ingresa aquí tu respuesta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ¿Que pasa si eliminas los pronombres personales en la normalización del texto? ¿Y si dejas solo los verbos? ¿Y si eliminamos los verbos? ¿Que pasa con el modelo large de SpaCy? ¿Que pasa si lematizas? ¿Hay alguna modificación al preprocesamiento de los documentos que implique una mejor distribución de tópicos (con el resto de los valores por default y el número de tópicos que seleccionaste en la pregunta 1)?\n",
    "\n",
    "_ingresa aquí tu respuesta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. ¿Que pasa si reduces el número de iteraciones en la inferencia a 50? ¿Que pasa si la aumentas a 200? ¿Y si reduces el numero de iteraciones del algoritmo de optimización a solo 1? ¿Si lo aumentas a 100 (ten cuidado, puede tardar mucho)? ¿Consideras que estos parámetros tienen mucha influencia en el resultado del método de LDA?\n",
    "\n",
    "_ingresa aquí tu respuesta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. ¿Que pasa si aceptas todas las palabras que aparezcan en menos del 80% de los documentos? ¿Que pasaría si limitas el vocabulario a las palabras que solamente aparezcan en el $\\frac{1.5}{\\text(numero\\ de\\ tópicos)}$ por ciento de los documentos? ¿Cual es el equilibrio que consideras que es el más acertado? \n",
    "\n",
    "_ingresa aquí tu respuesta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ¿Qué modelo te parece el mejor, después de probar con diferentes cosas?\n",
    "\n",
    "Si tienes más de un modelo que te parece interesante, puedes utilizar los métodos de medición de coherencia de los tópicos para tomar una desición.\n",
    "\n",
    "_ingresa aquí tu respuesta_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
